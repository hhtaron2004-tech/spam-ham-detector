{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df = pd.read_csv('spamhamdata.csv', delimiter='\\t', header=None)\n",
    "df.columns = [\"Category\", \"Text\"]\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.25, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "def to_alpha(s):\n",
    "    return re.sub(r'[^a-z ]', '', s.lower())\n",
    "\n",
    "\n",
    "word_list = []\n",
    "for text in train_df[\"Text\"].values:\n",
    "    for word in to_alpha(text).split():\n",
    "        if len(word) >= 2:\n",
    "            word_list.append(word)\n",
    "unique_word = np.unique(word_list)\n",
    "\n",
    "\n",
    "n = len(train_df)\n",
    "m = len(unique_word)\n",
    "train_matrix = pd.DataFrame(np.zeros((n, m)), columns=unique_word, index=train_df.index)\n",
    "\n",
    "\n",
    "for idx, text in zip(train_df.index, train_df[\"Text\"].values):\n",
    "    for word in to_alpha(text).split():\n",
    "        if word in unique_word:\n",
    "            train_matrix.loc[idx, word] += 1\n",
    "\n",
    "train_matrix[\"Category\"] = train_df[\"Category\"]\n",
    "\n",
    "\n",
    "cent_spam = train_matrix[train_matrix[\"Category\"]==\"spam\"].iloc[:, :-1].mean(axis=0).values\n",
    "cent_ham  = train_matrix[train_matrix[\"Category\"]==\"ham\"].iloc[:, :-1].mean(axis=0).values\n",
    "\n",
    "\n",
    "def category(x, cent_s, cent_h):\n",
    "    dist_s = np.linalg.norm(x - cent_s)\n",
    "    dist_h = np.linalg.norm(x - cent_h)\n",
    "    return \"ham\" if dist_h < dist_s else \"spam\"\n",
    "\n",
    "\n",
    "test_matrix = pd.DataFrame(np.zeros((len(test_df), m)), columns=unique_word, index=test_df.index)\n",
    "for idx, text in zip(test_df.index, test_df[\"Text\"].values):\n",
    "    for word in to_alpha(text).split():\n",
    "        if word in unique_word:\n",
    "            test_matrix.loc[idx, word] += 1\n",
    "\n",
    "\n",
    "misclassified = 0\n",
    "for i, row in enumerate(test_matrix.values):\n",
    "    if category(row, cent_spam, cent_ham) != test_df.iloc[i, 0]:\n",
    "        misclassified += 1\n",
    "\n",
    "print(\"Test samples:\", len(test_matrix))\n",
    "print(\"Misclassified:\", misclassified)\n"
   ],
   "metadata": {
    "id": "fJr3dChkrsGg",
    "ExecuteTime": {
     "end_time": "2026-01-11T01:54:50.171723Z",
     "start_time": "2026-01-11T01:54:24.031104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 1393\n",
      "Misclassified: 105\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ]
}
